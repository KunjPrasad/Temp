TODO:
i) Use of Swagger codegen to automatically make REST client. NOTE: add auth details for the client also!!
ii) Making custom middleware in JS by self - for use with Redux. This can now contain logic which are universal to all components and an aspect to all - like logs, adding auth, adding custom query params. Maybe, see https://medium.com/netscape/creating-custom-middleware-in-react-redux-961570459ecb
iii) use svg optimizer: https://jakearchibald.github.io/svgomg/
iv) React : if you render boolean "false" value, like: <div>{false}</div>, then it simply does not render
v) TO WRITE: In case haven't mentioned in earlier notes.. it's good to have tiered structure in redux data store.. by using successive createReducers(...) - rather than doing it flatly only on top level.
vi) See stackoverflow.com/questions/55139386/componentwillunmount-with-react-useeffect-hook -- on how to pass "most recent" state variable for use in hook equiv of componentWIllUnmount
vii) React-Redux-Router testing: see
-- https://github.com/reduxjs/redux-mock-store
-- https://www.npmjs.com/package/@testing-library/react **IMPORTANT** -- see advanced example in https://codesandbox.io/s/github/kentcdodds/react-testing-library-examples
viii) Iron Triangle -- does not cover divergent branching vs time-series convergent. This is where design patterns of most common use case and worker experience matters. 
ix) Use of React-router <Prompt> - if you want to prevent routing to a page. If using connected-react-router, then getUserconfirmation() has to be confirmed when making history object
--|---- Note the "isFirstRendering" property in action payload for @LOCATION_CHANGE - which is action of react-router. this is true only for first ever page rendered, else it is false!



DB design:
1) Foreign keys must be used to capture relations in table - this is known. If however, say, you have a "slug"/"uuid" column in a parent + child table one other thing possible is to have slug/uuid of related column be the same as that of the first column. 
-- Advantages: 
--|---- (1) It creates some sort of "understanding" of relation between the two tables "in-addition-to" being related by id. 
--|---- (2) Since slugs are unique - you can instead use "slug" to define the foreign key. So, it ends up behaving "like" 2 tables are using same primary key. 
--|----|----  **VERY VERY IMPORTANT** : A RELATED HUGE ADVANTAGE: Now you can use slug for foreign key. This way, when a query is made on child table, you can return parent's slug back without doing a join query, because child table already has it. Furthermore, if you delve back into actual rationale behind having a slug (https://stackoverflow.com/questions/427102/what-is-a-slug-in-django) - you'll notice that "slug" is supposed to provide context to a resource, so it is natural that every other related resource references the parent-resource using "slug" field (rather than "id" field) - to maintain the contextual coverage. Note that doing so does NOT prevent you from going back and using "id" instead for foreign key - since slugs are unique.. and not changed once it is set (See next point)
--|----|---- DO NOT DO ABOVE IF YOU'VE USED NATURAL KEY FOR SLUG - for same reason as you never use natural key for making "id" - because natural keys almost always change in span of product, and then you're left scrambling to change all tables ..or even worse, they go from being unique to non-unique.
-- Disadvantages: 
--|---- (1) Anyone knowing the "slug" of 1st table can now immediately know about the slugs used elsewhere :: BUT then.. having unknowable slugs shouldn't be your only security aspect
--|---- (2) What if the structure started as parent > child relation, but later more tables' foreign key were added. NOTE: (a) If, when adding other foreign key, you change the slug to be like `{foreignKey#1|foreignKey#2|...}`, that's bad - don't change the slug once it is set. That being done.. sure the original intent of the table was to have a parent > child relation, but now it grew beyond it.. that's fine.. the "slug" field still remains unique - which it should by definition - nothing wrong with it.

2) In terms of managing DB changes, realize that as time progresses, teams would find it better if the history of a DB-table file is tracked. This way, teams can identify what changes were done when, by whom, and under which ticket. This is one drawback of Django migration [[compared to Liquibase]] in that it meshes everything - so it's no longer clear what happened when/how/why. In this case, using Liquibase is better.
--|---- RELATED: **VERY VERY IMPORTANT**: Just like it's important to keep track of DB changes.. it is similarly a very good idea to include whole team in review - whenever any changes are made to model, like adding a property, modifying save() methods, etc. The reason being that when a change is made in model - that affects entire project.. so best to keep all in loop.

3) In previous notes, it is identified that any check that you want at DB level - that is the very core of your business, should go in Model's save() method. NOTE:
--|---- (i) A validation being in Model's save() method does NOT mean that you don't try to check for logic early on in serializer or beginning of view and raise error (..remember, don't be imperative in view.. you can, however, do exception translation). You should always do all validations as quickly possible before logic is made to go through.
--|---- (ii) Any failure arising out of Model's save() method for failing a validation MUST ONLY raise IntegrityError - and then leave it to view to modify it as needed. One exception would be if "unique failure" is raised by DB. It is ok to modify it as a ValidationFailure itself in DB - because DB "IS" the first place where such a check can be successfully done and without running into race conditions.
--|----|---- This is a big reason why having any "unique" checks in Serializer - that is auto-made by looking at Model's unique-together.. is just a wrong thing to do! DB "MUST BE ONE AND ONLY" authority to identify if there is uniqueness failure, and so delegating it to serializer is not a good design.
--|---- (iii) See Pg.149 of "2 scoops.." it is also possible to put validator in a model field.. that is also ok for model level validation.**HOWEVER, AGAIN** - do realize that it is best to put constraint on serializer, not on model unless absolutely required, and unless it covers each and every case. If you put validation on a model rather than serializer, and later want to remove it - then the burden will come to go to every serializer/form and add the check - which won't be bad ONLY if you are the only consumer of your code - because unit tests will tell you. However, if your code goes out.. then it becomes a travesty. Even more, different parts of the team may end up using the same model differently. BOTTOM LINE.. don't put validator on model - do on serializer to gain generic behavior -- ESSENTIALLY try avoiding adding DB constraints that are not given by SQL

4) Pg.148 of "2 scoops.." - lines at bottom of page - is a very good reason why you must always have your project model in one separate app by itself. You can make models in other apps, but they should just be abstract - leaving it on the main-model-app to turn them to concrete instance which are runtime wired to be used by services. So, in this case, you have a "runtime-DAG". How about compile time DAG? -- when you write services in apps that refer to models, they'll be doing so by using AbstractClass defined in those models. It means "Service requires/works-with object that look like those models -- so while you can inherit them to define concrete instances, you are restricted to only the behaviors as exposed by the corresponding abstract class.. this brings in abstraction". Now when you run, you use the corresponding service by wiring them with url and use the behavior. Thinking about it.. if you want a design where you want freedom to be able to package apps allowing other to modify it.. even the services in your app should be abstract - the idea being that now when someone makes url wiring, then turn abstract Views to concrete and use it.
--|---- **VERY VERY VERY IMPORTANT**: Thinking about it.. above creates an app where everything is abstract. So instead, let everything be concrete, incl. the models -- With the idea, that still, you don't directly use models in an app. You export them to separate app, and then make migration there.. and use those models. HOWEVER.. this has scope of error - what if someone runs migrations on the app by mistake rather than running migration in main model-app. THAT's why models everywhere else must be "Abstract", except in model-app.. but services, utils at other places can be concrete. 
--|---- **IMPORTANT**: It may be good to call the model-containing app as "core"; but better - keep it in your home-app.



UI DESIGN
1) If you want to allow update function on a resource (i.e. PUT / PATCH call), then it's best to display the resource info in a URL that ends with resource-id. That is a corresponding GET call on to which the update form can be shown as a modal. Most likely, you don't want to show resource within a table-list (either with table having rows that can be expanded to get full details, or each table-row itself showing full details) and allow update within there. One exception is if there's a special sub-type of update (i.e. updating only 1 field) that holds special meaning and so, the button to do so should be shown with each resource-entry, and resource-entry gets displayed within table-list.
2) NOT SURE if there's a way to pass config-properties to UI for different environment. A quick hack is to pass them to template in server, and then have that carry over to UI



CSS
1) See https://stackoverflow.com/questions/15733294/why-negative-right-margin-not-work -- if you have a scenario with parent-elem, then a child elem inside it, with child-elem being given negative margin.. then if child-elem is also given width:100%, then it's width is constrained by parent and may not become bigger even when adding negative margin!!



JS
1) Use moment.js and moment-timezone. Latter also allows using timezone like `America/Chicago', and getting common name for it like CST / CDT (is daylight-time aware in naming)

2) Use setInterval instead of setTimeout if you want recurring function after an interval. clear it using clearInterval.



REACT
1) If you react router tabs, a good option is to add as the last option a <Redirect> option that matches {match.url}, i.e. the url that causes entering the routed-tabs, and that redirects out to the default that you want set

2) React-router changes url and url can be used to store start-state of component. SO.. when you want to store basic state but don't want to change url (like showing some modal on accept / reject action) - then store those values in a useState under Router-level-component-wrapper for the renderer (the one with name ending ..ContainerRouter).
--|---- If the server endpoint you're mimicking for a UI action corresponds to anything other than a GET call, then don't update url. At most, you can add an action like create / update. Anything more.. or even a special action name that does POST / PUT call is an information leak and must not be put in url of rendering ui (NOTE.. the discussion is about url of rendering ui.. not url of server backend for which the design constraints are solidified)
--|---- In line with above.. when you are using above design to store a state that could've gone in url, but is not - and so the state is acting like router.. then it IS possible that the state also gets used to trigger some Redux action ..and be linked to some component. DO NOTE that this create 2 separate Redux-component for same top level url, so do ensure that the 2 don't collide wrongly.
--|---- If you have UI layout with tables such that clicking on table expands the row, then a proper url wiring should be that clicking on table also changes url and appends a slug. The advantage is that the table becomes stateless. The drawback is that this design cannot open more than 2 rows at once, nor could it have an "intermediate" view for item information. So, either condensed information for item is given when row is collapsed, or complete information is given when row is expanded, and there is no 3rd intermediary in between.

3) PREVENT NAVIGATION OUT: See https://stackoverflow.com/questions/32841757/detecting-user-leaving-page-with-react-router -- this is to prevent someone from navigating out of a page. Unfortunately React-router prompt (and also history.block) only allows sending a message! If you want to deliver the information via different component, or, in some cases don't want to give a Yes/No action, but only a "No" action, then that gets tricky. Using 'getUserConfirmation' from react router and this stackoverflow : https://stackoverflow.com/questions/56664622/how-to-display-component-using-react-router-prompt-to-prevent-or-allow-route-c is helpful.
--|---- HOWEVER.. above only does <Prompt> type behavior. Another possibility could be to add a middleware, intercept the @@LOCATION_CHANGE action and prevent it from going through unless a criteria is met. This allows doing "Alert" type control, where someone is just told they cannot navigate out, rather than give a yes/no answer. If you just want a custom action done.. like maybe, logging, that can also be done here.

4) Consider the case when you get an item/resource. This item has a behavior where one of its field can be updated to a different stage. Like approving/rejecting a submitted receipt. This can be a use case where you just update local redux rather than getting new detail on acceptance. However, do realize: (i) doing so cannot identify and concurrent updates to that/other fields of the resource - since you're not making server call. (ii) If call fails because that field has already been updated, you'll not know. Bottom line: This comes down to UI caching issue - and that is best done after the initial no-cache design, and cache is best applied as an aspect and depending on usage-pattern (not the use-case) -- This is important to understand: caching is ALWAYS based on improving "usage-pattern" and timing.. the use-case stays the same with or without it. As a compromise, one goes for strong-consistency to eventual-consistency



PYTHON
1) See https://docs.python.org/3.6/library/enum.html#functional-api -- you can create enum from list / dict. This is good when you want to create enum by combining other enums

2) See property() method - which is same as @property decorator. this, along with a lamba getter, can be used to add a property dynamically in same way as adding dynamic attribute. This is useful particularly for adding property to Enums created by above manner.

3) Use "#ignore: type"  -- on 1st line -- to suppress mypy errors

4) For python f strings, doing
    val=123
    print(f"{val:.2f}") <--- is a way to format decimal places within f-strings itself



DJANGO
1) See Pdf pg 160 of 2 scoops: Adding mixin for searching a common element-name, or maybe just common element (even foreign-key referenced ones..) that recurs ..by adding it in mixin. This highlights importance for having a naming strategy!! 
--|---- HOWEVER.. note that in the book it's added in 'views.py' file for the app. You must be careful in where/how it is added. If a function is added in views.py, it won't be available outside (going by DAG dependence). But what if it gets needed in serializer, etc.. See own notes below

2) From definitions like SlugRelatedField.. realize that it is expected by design/common-usage for serializer to return corresponding DB entity for the field. So, there's nothing wrong / magical about doing so. 
--|---- **VERY VERY IMPORTANT**: In a previous note, it is suggested that it may not be a good thing to use HiddenField. However, looking at code of CreateModelMixin, note that the request flow goes through serializer and then to viewset. So, it's not clear on why using HiddenField is a bad thing!! It's like for data that is read from request, but instead of coming from request.body, it's coming from somewhere.. but is still a data that is needed. So, don't think using HiddenField is wrong. Also, it's not like serializer is called before permissions are applied - so it's not even the case that having HiddenField will bypass permissions. THE ONLY thing to be careful about is that you shouldn't put any logic in HiddenField that can also be used in get_queryset() method. You must keep HiddenField for purpose of POST/PUT calls that require some form of data deserialization. For GET / LIST type calls that use get_queryset(), any necessary logic should be in supporting mixin methods. 
--|----|---- **VERY VERY IMPORTANT**: This also brings up a good coding pattern.. start with GET / LISt calls first. Make necessary utilities. IF AND ONLY IF there is still a need for hiddenField, etc. then incorporate it, else don't. An advantage of doing so is that methods which take "request" as an argument are restricted to within view or viewMixin. Had this logic been also moved to serializers, then this method would have to be moved to some utils class.. which is a bit weird, because utils should be common utilities related to class function and not related to exposing classes over net as a request! SO.. prevent having duplicate logic for forms, serializers, views. IF in doing so, you miss certain validation, then likely they need to go in save() method.. or if it is a perform_create() or perform_update call, then use get_object_or_404, and catch NotFound to instead raise ValidationException.. with the understanding that an exception is raised soonest in process flow, if it needs raising. Now, when control goes to DB, it only raises IntegrityError.. except when doing uniqueness check, because DB is the first and only place that can do so.. so instead change it to ValidationError.
--|---- One drawback of this design is that every DB call - when deserializing user data - makes multiple DB call - one for each nested object. So, it is a bit inefficient.. However, going by REST designs - needing to query for a sub-field when making POST/PUT call is very infrequent and so this implementation doesn't hurt.. and instead gives a lot of flexibility and reusability. When making DB calls during serialization of response - if this becomes a concern, then just properly use select_related(), only() methods.

3) Say the requirement is to capture both existing data and user data on failure. 2 scoops pdf page 172 gives an example. There are alternates possible --HOWEVER-- first thing, always think whether this is a good/needed behavior. Anytime you capture information, it is susceptible to leaking and can be security nightmare. It may not be good idea.
--|---- The equivalent of this example for serializers would be to modify the update() method [[not create() method]], wrap with a try/catch and if an exception is raised, then save the existing and new entry details. However, this goal can also be achieved in various other ways.. (i) by modifying save() method - which then also logs during create() call; (ii) by logging on failure and standardizing the log using decorators; (iii) Not sure if there is a Django way to add aspects / handlers to save every save() call automatically.. can use signal() also

4) prefetch_related: Note that prefetch_related calls are always done regardless of whether that info gets serialized or not. So, unless you actually need it, don't do a prefetch-related. However, if there is even a slightest need - i.e. you'll be returning a list and many (if not all) entries will be examined, then doing prefetch_related is a good call because calls are made using "IN" filtering in db. So, multiple results are obtained at once. However, expect it to also tad increase the serialization time since large results are being sent. 
--|---- RELATED: If you don't need all info right then and there, then best is to get those in corresponding detail call. **VERY VERY IMPORTANT: Get the data only when needed ..and identify the "need" based on use-case AND usage-pattern**
--|---- Keep a balance between doing prefetch_related vs making a new endpoint. (i) If you are doing prefetch_related for a related item that is a list, then it's best to turn it to an endpoint, specially if you also want to provide create-function for that related-item (This way UI can query for most updated list once the create is done). (ii) However, if the use case requires that when retrieving the main list element, that it also gives a related child list, then better to use pretch_related and pull in data. (iii) There can be scenario where to you main element, you have related#1 and related#2, but there is also relation between related#1 and related#2. In this case, you may want to group the prefetched related#2 by prefetched related#1. Seems like there isn't a simple way to do so in Django and this logic will need to go in serializer

5) If you want to have equivalent to "single table design" in Django.. it is best done using enum and defining property on enum and setting enum values such that one eventually gets a "delegation effect" -- making single class have different behavior based on value of single field.
--|---- ON THAT NOTE: Maybe avoid the Django polymorphic package -- looked at it and didn't feel comfortable. One must be able to better design their use-case using Proxy / Enum-based / Abstract-table based design.
--|---- **VERY VERY VERY IMPORTANT**: Consider a use-case like: In a table T1, if column col-1 has value "VAL-T2", then column col-2 of table T1 refers to "id" (or slug) of Table T2. If instead col-1 of table T1 has value "VAL-T3", then column col-2 of table T1 refers to "id" of Table T3. And in doing so, you don't put foreign key relation between col-2 of table T1 (since it can refer to any of 2 tables based on value in column col-1). This seems like a "single table design" -- but, NEVER EVER DO SO!!! 
**NEVER EVER DELATE OUT A FOREIGN-KEY RELATION**. 
**INSTEAD DO**: (i) have separate columns nullable columns col-T2 and col-T3 in table T1 which have foreign key relation with Table T2 and T3 respectively; (ii) In your save method for table T1, add referential check that only one of col-T2 and col-T3 is null, (iii) In your serializer, pass a context that helps serializer identify the case it's being used for for VAL-T1 case or VAL-T2 case and have it verify that the corresponding value is non-null [[NOTE: do "value" based check in serializer, not in save() method of Model. Keep only the referential checks in save() method -- something that could have been a DB constraint by design and before looking at any data, but couldn't be due to limitations of DDL statements]]
However, in above, if you instead want to store a value and not reference to any other column (like some json, and not a foreign key), whose value gets interpreted based on content.. then that is something that can be made polymorphic and interpreted based on Enum value stored in some other column. This is ok since it's not a foreign-key relationship